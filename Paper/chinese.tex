\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{makeidx}
\usepackage{listings}
\usepackage{color}
\usepackage{minted}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{makeidx}
\usepackage{graphicx}
\usepackage{xeCJK}
\usepackage{caption2}
\captionstyle{hang}
\definecolor{mygreen}{rgb}{0,0.6,0}
\definecolor{mygray}{rgb}{0.5,0.5,0.5}
\definecolor{mymauve}{rgb}{0.58,0,0.82}


% Default fixed font does not support bold face
\DeclareFixedFont{\ttb}{T1}{txtt}{bx}{n}{12} % for bold
\DeclareFixedFont{\ttm}{T1}{txtt}{m}{n}{12}  % for normal
\usepackage{fontspec}
\setmonofont{Consolas}
% Custom colors
\usepackage{color}
\definecolor{deepblue}{rgb}{0,0,0.5}
\definecolor{deepred}{rgb}{0.6,0,0}
\definecolor{deepgreen}{rgb}{0,0.5,0}

\usepackage{listings}

% Python style for highlighting
\newcommand\pythonstyle{\lstset{
language=Python,
basicstyle=\ttfamily,
otherkeywords={self},             % Add keywords here
keywordstyle=\ttfamily\color{deepblue},
emph={MyClass,__init__},          % Custom highlighting
emphstyle=\ttfamily\color{deepred},    % Custom highlighting style
stringstyle=\color{deepgreen},
frame=tb,                         % Any extra options here
showstringspaces=false            % 
}}


% Python environment
\lstnewenvironment{python}[1][]
{
\pythonstyle
\lstset{#1}
}
{}

% Python for external files
\newcommand\pythonexternal[2][]{{
\pythonstyle
\lstinputlisting[#1]{#2}}}

% Python for inline
\newcommand\pythoninline[1]{{\pythonstyle\lstinline!#1!}}
\usepackage{amssymb}
\usepackage{makeidx}

\usepackage{graphicx}
\usepackage{float}
\usepackage{hyperref}
%\usepackage[Sonny]{fncychap}
\floatstyle{boxed}
\restylefloat{figure}
\setCJKmainfont[BoldFont=SimHei]{SimSun}
\usepackage{graphicx}
\setCJKmonofont{SimSun}% 设置缺省中文字体
\parindent 2em   %段首缩进
\makeindex
\begin{document}
\input{title_c.tex}

\input{overview_c.tex}

\newpage
\section{构造}
\input{body_c.tex}
\section{结论}
\input{future_c.tex}
\section{附录}
\newpage
\appendix
\section{\\Camshift.py} \label{App:AppendixA}
\begin{python}
#!/usr/bin/env python

import numpy as np
import cv2
import video
from utils import mark

size_treshold = 4
side_inc = 2
size_maxium = 256
flag= True
MorphOps = False
Channel = False
Realtime = False
Update = False

def abs(n):
    if n>0:
        return n
    return -n

def get_window_size(window):
    x0, y0, x1, y1 = window
    size = abs(x1) * abs(y1)
    return size

def get_increased_window(window):
    xx0, yy0, xx1, yy1 = window
    xx0 -= side_inc
    yy0 -= side_inc
    xx1 += side_inc
    yy1 += side_inc
    xx0, yy0, xx1, yy1 = max(0, xx0), max(0, yy0), min(size_maxium, max(1, xx1)), min(size_maxium, max(1, yy1))# Make the square's size at least 1 pixel.
    new_window = (xx0, yy0, xx1, yy1)
    return new_window

class App(object):
    def __init__(self, video_src):
        self.cam = video.create_capture(1)
        ret, self.frame = self.cam.read()
        cv2.namedWindow('camshift')
        cv2.setMouseCallback('camshift', self.onmouse)
        self.mouse_state = 0
        self.selection = None
        self.drag_start = None
        self.tracking_state = 0
        self.show_backproj = False

    def onmouse(self, event, x, y, flags, param):
        x, y = np.int16([x, y]) # BUG
        #print (x,y)
        debug={}
        bkp=flags
        if event == cv2.EVENT_LBUTTONDOWN:
            #print (x,y)
            self.drag_start = (x, y)
            self.tracking_state = 0
            self.mouse_state = 1
        elif event == cv2.EVENT_MOUSEMOVE:
            if self.mouse_state:
                h, w = self.frame.shape[:2]
                xo, yo = self.drag_start
                x0, y0 = np.maximum(0, np.minimum([xo, yo], [x, y]))
                x1, y1 = np.minimum([w, h], np.maximum([xo, yo], [x, y]))
                #print (x0,y0,x1,y1)
                self.selection = None
                if x1-x0 > 0 and y1-y0 > 0:
                    self.selection = (x0, y0, x1, y1)
                    #print self.selection
        elif event == cv2.EVENT_LBUTTONUP:
            self.mouse_state = 0
            self.drag_start = None
            flag= False
            if self.selection is not None:
                self.tracking_state = 1 
    def show_hist(self):
        bin_count = self.hist.shape[0]
        bin_w = 24
        img = np.zeros((256, bin_count*bin_w, 3), np.uint8)
        for i in xrange(bin_count):
            h = int(self.hist[i])
            cv2.rectangle(img, (i*bin_w+2, 255), ((i+1)*bin_w-2, 255-h), (int(180.0*i/bin_count), 255, 255), -1)
        img = cv2.cvtColor(img, cv2.COLOR_HSV2BGR)
        cv2.imshow('hist', img)

    def run(self):
        global Update
        global MorphOps
        global Channel
        global Realtime
        while True:

            ret, self.frame = self.cam.read()
            vis = self.frame.copy()
            hsv = cv2.cvtColor(self.frame, cv2.COLOR_BGR2HSV)
            mask = cv2.inRange(hsv, np.array((0., 60., 32.)), np.array((180., 255., 255.)))
            mask = cv2.inRange(hsv, np.array((0., 0., 0.)), np.array((180., 255., 255.)))
            if self.selection:
                x0, y0, x1, y1 = self.selection
                self.track_window = (x0, y0, x1-x0, y1-y0)
                hsv_roi = hsv[y0:y1, x0:x1]
                mask_roi = mask[y0:y1, x0:x1]
                
                if Channel:
                    hist = cv2.calcHist( [hsv_roi], [0,1], mask_roi, [16,5], [0, 180, 0 ,256] )
                else:
                    hist = cv2.calcHist( [hsv_roi], [0], mask_roi, [16], [0, 180] )
                cv2.normalize(hist, hist, 0, 255, cv2.NORM_MINMAX)
                self.hist = hist.reshape(-1)
                self.show_hist()

                vis_roi = vis[y0:y1, x0:x1]
                cv2.bitwise_not(vis_roi, vis_roi)
                vis[mask == 0] = 0

            if self.tracking_state == 2:
                if Channel:
                    prob = cv2.calcBackProject([hsv], [0,1], self.hist, [0, 180, 0, 256], 1)
                else:
                    prob = cv2.calcBackProject([hsv], [0], self.hist, [0, 180], 1)
                prob &= mask
                term_crit = ( cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1 )
                self.previous_window = self.track_window
                kernel = np.ones((5,5),np.uint8)
                if MorphOps:
                    prob = cv2.morphologyEx(prob, cv2.MORPH_OPEN, kernel)
                    prob = cv2.morphologyEx(prob, cv2.MORPH_CLOSE, kernel)
                prob = cv2.GaussianBlur(prob,(5,5),0)

                track_box, self.track_window = cv2.CamShift(prob, self.track_window, term_crit)
                if get_window_size(self.track_window) <= size_treshold:
                    self.track_window = get_increased_window(self.previous_window)
                    self.tracking_state = 2
                else :
                    self.tracking_state = 1
                font = cv2.FONT_HERSHEY_SIMPLEX
                print "Target Missing."
                cv2.putText(vis,'Target Missing',(10,400), font, 1,(255,255,255),2,1)

            if self.tracking_state == 1:
                self.selection = None
                if Channel:
                    prob = cv2.calcBackProject([hsv], [0,1], self.hist, [0, 180, 0, 256], 1)
                else:
                    prob = cv2.calcBackProject([hsv], [0], self.hist, [0, 180], 1)
                prob &= mask
                term_crit = ( cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1 )
                self.previous_window = self.track_window
                kernel = np.ones((5,5),np.uint8)
                if MorphOps:
                    prob = cv2.morphologyEx(prob, cv2.MORPH_OPEN, kernel)
                    prob = cv2.morphologyEx(prob, cv2.MORPH_CLOSE, kernel)
                prob = cv2.GaussianBlur(prob,(5,5),0)
                track_box, self.track_window = cv2.CamShift(prob, self.track_window, term_crit)
                if get_window_size(self.track_window) <= size_treshold:
                    self.track_window = get_increased_window(self.previous_window)
                    self.tracking_state = 2
                if self.show_backproj:
                    vis[:] = prob[...,np.newaxis]
                xx0, yy0, xx1, yy1 = self.track_window
                img_roi = self.frame[yy0 : yy0 + yy1, xx0 : xx0 + xx1]
                cv2.imshow("Tracking Window",img_roi)
                if get_window_size(self.track_window) >= size_treshold and Update:
                    self.bkp=self.hist
                    font = cv2.FONT_HERSHEY_SIMPLEX
                    cv2.putText(vis,'Updating...',(10,200), font, 1,(255,255,255),2,1)
                    xx0, yy0, xx1, yy1 = self.track_window
                    xx1 /= 3
                    yy1 /= 3
                    xx0 += xx1
                    yy0 += yy1
                    if xx1 > 0 and yy1 > 0:
                        print self.track_window
                        hsv_roi = hsv[yy0 : yy0 + yy1, xx0 : xx0 + xx1]
                        mask_roi = mask[yy0 : yy0 + yy1 , xx0 : xx0 + xx1]
                        cv2.imshow("Tracking Window",hsv_roi)
                        hist = cv2.calcHist( [hsv_roi], [0], mask_roi, [16], [0, 180] )
                        cv2.normalize(hist, hist, 0, 255, cv2.NORM_MINMAX)
                        print cv2.compareHist(hist.reshape(-1), self.bkp, 0)
                        self.hist = hist.reshape(-1)
                    self.show_hist()
                    if not Realtime:
                        Update = not Update
                font = cv2.FONT_HERSHEY_SIMPLEX
                cv2.putText(vis,str(track_box[0]),(10,400), font, 1,(255,255,255),2,1)
                print str(track_box[0])
                #try: cv2.ellipse(vis, track_box, (0, 0, 255), 2)
                #except: print track_box
                mark.draw_machine_mark(60, track_box[0], vis)

            #cv2.imshow('Original Footage',self.frame)
            if flag:
                cv2.imshow('camshift', vis)

            ch = 0xFF & cv2.waitKey(5)
            if ch == 27:
                break
            if ch == ord('b'):
                self.show_backproj = not self.show_backproj
            if ch == ord('m'):
                MorphOps = not MorphOps
            if ch == ord('c'):
                Channel = not Channel
            if ch == ord('u'):
                Update = not Update
            if ch == ord('r'):
                Realtime = not Realtime
        cv2.destroyAllWindows()


if __name__ == '__main__':
    import sys
    try: video_src = sys.argv[1]
    except: video_src = 0
    print __doc__
    App(video_src).run()

\end{python}
\newpage
\section{\\Bi_calibration.py} \label{App:AppendixB}}
% the \\ insures the section title is centered below the phrase: Appendix B
\begin{python}
import numpy as np
import cv2
import os
import sys, getopt
from glob import glob

img_set = '2*.jpg'
img_names = glob(img_set)

chessboard_size = (9, 6)
pattern_points = np.zeros( (np.prod(chessboard_size), 3), np.float32 )
pattern_points[:,:2] = np.indices(chessboard_size).T.reshape(-1, 2)

obj_points = []
img_points = []
h, w = 0, 0
for name in img_names:
    print 'Detecting chessboard on %s...' % name,
    img = cv2.imread(name, 0)
    h, w = img.shape[:2]
    found, corners = cv2.findChessboardCorners(img, chessboard_size)
    if found:
        term = ( cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_COUNT, 30, 0.1 )
        cv2.cornerSubPix(img, corners, (5, 5), (-1, -1), term)
        vis = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
        cv2.drawChessboardCorners(vis, chessboard_size, corners, found)
        cv2.imshow('Corners', vis)
        cv2.imwrite('proc_'+name,vis)
        cv2.waitKey(200)
    if not found:
        print 'chessboard not found'
        continue
    img_points.append(corners.reshape(-1, 2))
    obj_points.append(pattern_points)
    
    print 'ok'

rms, camera_matrix, dist_coefs, rvecs, tvecs = cv2.calibrateCamera(obj_points, img_points, (w, h))
print "RMS:", rms
print "camera matrix:\n", camera_matrix
print "distortion coefficients: ", dist_coefs.ravel()
img = cv2.imread('1.jpg')
h,  w = img.shape[:2]
newcameramtx, roi=cv2.getOptimalNewCameraMatrix(camera_matrix,dist_coefs,(w,h),1,(w,h))
# undistort
dst = cv2.undistort(img, camera_matrix, dist_coefs, None, newcameramtx)

# crop the image
x,y,w,h = roi
dst = dst[y:y+h, x:x+w]
cv2.imwrite('calibresult.png',dst)

chessboard_size = (9, 6)
pattern_points = np.zeros( (np.prod(chessboard_size), 3), np.float32 )
pattern_points[:,:2] = np.indices(chessboard_size).T.reshape(-1, 2)

#Define Cameras
cap0 = cv2.VideoCapture(0)
cap1 = cv2.VideoCapture(1)

obj_points = []
img_points = []
img_points2 = []

chessboard_size = (9, 6)
pattern_points = np.zeros( (np.prod(chessboard_size), 3), np.float32 )
pattern_points[:,:2] = np.indices(chessboard_size).T.reshape(-1, 2)

while True:
	ret, img = cap0.read()
	ret, img2 = cap1.read()
	img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
	img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)
	found, corners = cv2.findChessboardCorners(img, chessboard_size)
	found1, corners2 = cv2.findChessboardCorners(img2, chessboard_size)
	if found and found1:
		term = ( cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_COUNT, 30, 0.1 )
		cv2.cornerSubPix(img, corners, (5, 5), (-1, -1), term)
		cv2.cornerSubPix(img2, corners2, (5, 5), (-1, -1), term)
		vis = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
		vis2 = cv2.cvtColor(img2, cv2.COLOR_GRAY2BGR)
		cv2.drawChessboardCorners(vis, chessboard_size, corners, found)
		cv2.drawChessboardCorners(vis2, chessboard_size, corners2, found)
		img=vis
		img2=vis2
		img_points.append(corners.reshape(-1, 2))
		img_points2.append(corners2.reshape(-1, 2))
		obj_points.append(pattern_points)
	cv2.imshow('Image', img)
	cv2.imshow('Image2', img2)
	ch = 0xFF & cv2.waitKey(1)
	if ch == 27:
		break	
retval, cameraMatrix1, distCoeffs1, cameraMatrix2, distCoeffs2, R, T, E, F = cv2.stereoCalibrate(obj_points,
																							img_points,
																							img_points2,
																							(640,480),
																							cameraMatrix1=camera_matrix,
																							distCoeffs1=dist_coefs,
																							cameraMatrix2=camera_matrix,
																							distCoeffs2=dist_coefs,
																							)
print "-cameraMatrix1:"
print cameraMatrix1
np.save('cameraMatrix1.npy', cameraMatrix1)
print "-distCoeffs1:"
print distCoeffs1
np.save('distCoeffs1.npy', distCoeffs1)
print "-cameraMatrix2:"
print cameraMatrix2
np.save('cameraMatrix2.npy', cameraMatrix2)
print "-distCoeffs2:"
print distCoeffs2
np.save('distCoeffs2.npy', distCoeffs2)
print "-R:"
print R
np.save('R.npy', R)
print "-T:"
print T
np.save('T.npy', T)
print "-E:"
print E
np.save('E.npy', E)
print "-F:"
print F
np.save('F.npy', F)


\end{python}

\newpage
\input{bib_c.tex}
\end{document}